<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images">
  <meta name="keywords" content="Inverse Rendering, Indoor Scenes, Low Dynamic Range">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>IRIS: Inverse Rendering of Indoor Scenes from Low Dynamic Range Images</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./images/figures/eye.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- Style and Script from result template -->
  <style>
    /* html {
      background-color: #eee;
      margin: 0;
      scroll-behavior: smooth;
    }
    body {
      font-family: -apple-system, BlinkMacSystemFont, helvetica, arial, sans-serif;
      font-size: 11pt;
      line-height: 1.2em;
      font-size: 14px;
      line-height: 18px;
      font-weight: 300;
      text-align: left;
      background-color: white;
      color: #333;
      width: 840px;
      margin: 0 auto;
      padding: 18px 12px;
      box-shadow: 0 0 10px 0 rgba(0, 0, 0, 0.2);
      -webkit-font-smoothing: antialiased;
    }
    h1 {
      text-align: center;
      text-align: left;
    }
    h1 {
      font-size: 1.5em;
      margin-top: 2em;
      margin-bottom: 1em;
    }
    h2 {
      font-size: 1.15em;
      margin-top: 1.5em;
      margin-bottom: 0;
    } */
    h3 span:last-child {
      float: right;
      font-weight: bold;
      color: #333;
      background-color: #ddd;
      border-radius: 0.2em;
      padding: 0 0.3em 0 0.35em;
      font-size: 0.8em;
      font-family: verdana;
    }
    h3 a {
      color: inherit;
    }
    /* p, ul {
      margin-top: 0.6em;
      margin-bottom: 1.1em;
    }  */
    /* ul {
      padding-left: 2em;
    }
    a {
      text-decoration: underline; color: black;
    }
    a:hover {
      text-decoration: underline; color: gray;
    }
    a.invert {
      text-decoration: none; color: white; font-weight: bold;
    }
    a.invert:hover {
      text-decoration: none; color: #ccc;
    }
    
    div.links {
      text-align: center;
      justify-content: space-around;
      margin-top: 0.5em;
      margin-bottom: 2.5em;
      line-height: 2.5em;
    }
    div.links a {
      text-decoration: none;
    }
    div.links a:hover {
      text-decoration: none;
    }
    div.links span {
      background-color: #444;
      color: white;
      font-weight: bold;
      border-radius: 0.5em;
      padding: 0.4em 1em 0.5em 1em;
      margin: 0 0.2em;
      white-space: nowrap;
    }
    div.links span:hover {
      background-color: #777;
    }
    div.links img {
      height: 1em;
      vertical-align: -10%;
      filter: brightness(0%) saturate(100%) invert(100%) sepia(0%) saturate(0%) hue-rotate(24deg) brightness(100%) contrast(100%);
    }
    
    /* wrap long lines */
    /* pre {
      white-space: pre-wrap;
      white-space: -moz-pre-wrap;
      white-space: -o-pre-wrap;
      word-wrap: break-word;
      text-align: left;
    }
    pre {
      border-left: 5px solid #eee;
      padding-left: 5px;
    } */
    /* @media only screen and (max-device-width: 480px) {
      html { background-color: white; }
      body { width: 97%; box-shadow: none; }
      body {
        -webkit-text-size-adjust: 100%;
        -moz-text-size-adjust:    100%;
        -ms-text-size-adjust:     100%;
      }
      body { font-size: 1.25em; font-size: 2.1vw; line-height: 1.6em; line-height: 2.7vw; }
    }
    @media print {
      html { background-color: white; }
      body { width: 97%; box-shadow: none; }
    } */
    /*
    button {
      padding: 0.5em 0.75em;
      margin: 0.4em 0.4em;
      min-width: 18ch;
      max-width: 18ch;
      text-align: left;
      background-color: #ddd;
      color: #333;
      border-radius: 5px;
      border: none;
      cursor: pointer;
    
      @media screen and (-ms-high-contrast: active) {
        border: 2px solid currentcolor;
      }
    }
    
    button.on {
      background-color: #333;
      color: #bbb;
    }
    
    button.result {
      padding: 0.5em 0.75em;
      margin: 0.4em 0.4em;
      min-width: 18ch;
      max-width: 18ch;
      text-align: left;
      background-color: #ddd;
      color: #333;
      border-radius: 5px;
      border: none;
      cursor: pointer;
    
      @media screen and (-ms-high-contrast: active) {
        border: 2px solid currentcolor;
      }
    }
    
    button.result.on {
      background-color: #333;
      color: #bbb;
    } */
    
    div.result button {
      padding: 0.5em 0.75em;
      margin: 0.4em 0.4em;
      min-width: 18ch;
      max-width: 18ch;
      text-align: left;
      background-color: #ddd;
      color: #333;
      border-radius: 5px;
      border: none;
      cursor: pointer;
    
      @media screen and (-ms-high-contrast: active) {
        border: 2px solid currentcolor;
      }
    }
    
    div.result button.on {
      background-color: #333;
      color: #bbb;
    }

    div.frame {
      max-width: 1200px;
      /* max-width: 70%; */
      width: 100%;
      margin: auto;
    }
    
    p.btncap {
      margin: 0.4em 0.4em;
      padding: 0 0.2em;
      color: #333;
      border-bottom: 2px solid #333;
      font-weight: bold;
      font-style: italic;
      font-size: 0.8em;
    }
    
    /* .center {
      text-align: center;
    } */
    .flex {
      display: flex;
    }
    
    /* .desc {
      margin: 1.5em 0.4em;
    } */
    /* .wider_buttons button {
      display: block;
      min-width: 18ch;
      max-width: 18ch;
    } */
    /*
    .horns button {
      text-align: center;
      display: block;
      min-width: 27ch;
      width: 180px;
    } 
    .tarot button {
      text-align: center;
      display: block;
      min-width: 11ch;
      width: 95px;
    }*/
    button {
      display: block;
    }
    
    video {
      display: none;
      width: 1000px;
      height: auto;
      min-width: 300px;
      /* max-width: 540px;
      width: auto; */
      /* height: 540px; */
      margin: 0.4em;
    }
    video.on {
      display: block;
    }
    video.car {
      display: block;
    }

    img[id^="img"], img[id*="image"] {
      display: none;
      width: 1000px; /*640px*/
      height: auto;
      min-width: 300px;
      /* max-width: 540px;
      width: auto; */
      /* height: 540px; */
      margin: 0.4em;
    }
    img.on {
      display: block;
    }

    /*
    img[id^="img"] {
      display: none;
      max-width: 540px;
      max-height: 540px;
      width: auto;
      height: auto;
      margin: 0.4em;
    }
    img.shiny_img {
      display: none;
      width: 504px;
      height: 284px;
      margin: 0.4em;
    }
    img.on {
      display: block;
    }
    
    .teaser {
    }
    
    .teaser video {
      width: 410px;
    }
    
    .teaser .crop {
      overflow: hidden;
      height: 307px;
    }
    
    .teaser .horns video {
      height: 307px;
      margin-top: 0px;
    }
    
    .teaser .tarot video {
      height: 410px;
      margin-top: -65px;
    }
    
    .closeup {
      width: 100px;
    }
    
    .closeup img {
      width: 100%;
    }
    
    .closeup div {
      width: 100%;
      font-size: 1em;
      font-weight: 400;
      text-align: center;
    }
    
    .closeup em {
      font-weight: 600;
      font-style: normal;
    } */
    
    
    div.imgcontainer {
      display: none;
      width: 540px;
      height: 540px;
      margin: 0.4em;
    }
    div.on {
      display: block;
    }
    
    div.imgcontainer img {
      display: block;
      max-width: 100%;
      max-height: 100%;
      width: auto;
      height: auto;
    }
   
    
    /* .authors {
      display: flex;
      justify-content: space-evenly;
      text-align: center;
    }
    
    .authors div {
      width: 25ch;
      margin-top: 10px;
      margin-bottom: 10px;
    } */
    /* 
    .authors div p:first-child {
      font-size: 1.1em;
      margin-bottom: 0.5em;
    }
    
    .authors div p:last-child {
      margin-top: 0.5em;
      font-size: 0.95em;
    }
    
    .justify {
      text-align: justify;
    }
    
    .shadow {
      box-shadow: 0 4px 8px 0 rgba(0, 0, 0, 0.2), 0 6px 20px 0 rgba(0, 0, 0, 0.19);
    }
    
    em {
      font-weight: bold;
    }
    
    .tooltip {
      position: relative;
      display: inline-block;
      text-decoration: underline;
      text-decoration-style: dotted;
      cursor: pointer;
    }
    
    .tooltip .tooltiptext {
      visibility: hidden;
      width: 120px;
      background-color: black;
      color: #fff;
      text-align: left;
      border-radius: 6px;
      padding: 5px;
      position: absolute;
      z-index: 1;
      bottom: 150%;
      left: 50%;
      margin-left: -60px;
    }
    
    .tooltip .tooltiptext::after {
      content: "";
      position: absolute;
      top: 100%;
      left: 50%;
      margin-left: -5px;
      border-width: 5px;
      border-style: solid;
      border-color: black transparent transparent transparent;
    }
    
    .tooltip:hover .tooltiptext {
      visibility: visible;
    } */
    
  </style>
    <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    <script>
    class ObjectHandler {
      constructor(n_scenes, n_objects, scene_button_id, object_button_id, object_tag_id) {
        this.n_scenes = n_scenes;
        this.n_objects = n_objects;
      
        this.scene_button_id = scene_button_id;
        this.object_button_id = object_button_id;
        this.object_tag_id = object_tag_id;
      }
    
      get subdir() {
        throw new Error("subdir() getter must be implemented.")
      }
    
      get ext() {
        throw new Error("ext() getter must be implemented.")
      }
    
      on_object_selected(o) {
        // do nothing
      }
    
      on_object_deselected(o) {
        // do nothing
      }
    
      for_each_object(fn) {
        for (let i = 0; i < this.n_objects; i++) {
          let o = document.getElementById(this.object_tag_id + i.toString());
          fn(o);
        }
      }
    
      get first_object() {
        return document.getElementById(this.object_tag_id + "0");
      }
    
      select_object(j) {
        for (let i = 0; i < this.n_objects; i++) {
          let o = document.getElementById(this.object_tag_id + i.toString());
          let b = document.getElementById(this.object_button_id + i.toString());
          if (i == j) {
            b.className = "on";
            o.style.display = "block";
            this.on_object_selected(o);
          } else {
            b.className = "";
            o.style.display = "none";
            this.on_object_deselected(o);
          }
        }
      }
    
      select_scene(j) {
        let scene_name = document.getElementById(this.scene_button_id + j.toString()).value;
        for (let i = 0; i < this.n_scenes; i++) {
          document.getElementById(this.scene_button_id + i.toString()).className = (i == j ? "on" : "");
        }
        for (let i = 0; i < this.n_objects; i++) {
          let image_name = document.getElementById(this.object_button_id + i.toString()).value;
          let v = document.getElementById(this.object_tag_id + i.toString());
          v.src = this.subdir + "/" + scene_name + "_" + image_name + "." + this.ext;
        }
      }
    
      register() {
        for (let i = 0; i < this.n_scenes; i++) {
          document.getElementById(this.scene_button_id + i.toString()).addEventListener("click", function() { this.select_scene(i); }.bind(this, i));
        }
      
        for (let i = 0; i < this.n_objects; i++) {
          document.getElementById(this.object_button_id + i.toString()).addEventListener("click", function() { this.select_object(i); }.bind(this, i));
        }
      }
    }

    class ObjectHandler3 {
      constructor(n_scenes, n_methods, n_results, scene_button_id, method_button_id, result_button_id, object_tag_id) {
        this.n_scenes = n_scenes;
        this.n_methods = n_methods;
        this.n_results = n_results;
        this.n_objects = n_methods * n_results;
        this.scene_button_id = scene_button_id;
        this.method_button_id = method_button_id;
        this.result_button_id = result_button_id;
        this.object_tag_id = object_tag_id;
      }
    
      get subdir() {
        throw new Error("subdir() getter must be implemented.")
      }
    
      get ext() {
        throw new Error("ext() getter must be implemented.")
      }
    
      on_object_selected(o) {
        // do nothing
      }
    
      on_object_deselected(o) {
        // do nothing
      }
    
      for_each_object(fn) {
        for (let mi = 0; mi < this.n_methods; mi++) {
          for (let ri = 0; ri < this.n_results; ri++) {
            let o = document.getElementById(this.object_tag_id + "_" + mi.toString() + "_" + ri.toString());
            fn(o);
          }
        }
      }
    
      get first_object() {
        return document.getElementById(this.object_tag_id + "_0_0");
      }
    
      select_object(method, result) {
        for (let mi = 0; mi < this.n_methods; mi++) {
          for (let ri = 0; ri < this.n_results; ri++) {
            let o = document.getElementById(this.object_tag_id + "_" + mi.toString() + "_" + ri.toString());
            if (method == mi && result == ri) {
              o.style.display = "block";
              this.on_object_selected(o);
            } else {
              o.style.display = "none";
              this.on_object_deselected(o);
            }
          }
        }
      }
    
      select_result(result) {
        for (let ri = 0; ri < this.n_results; ri++) {
          document.getElementById(this.result_button_id + ri.toString()).className = (ri == result ? "on" : "");
        }
        let method = 0;
        for (let mi = 0; mi < this.n_methods; mi++) {
          if (document.getElementById(this.method_button_id + mi.toString()).className == "on") {
            method = mi;
          }
        }
        this.select_object(method, result);
      }
    
      select_method(method) {
        for (let mi = 0; mi < this.n_methods; mi++) {
          document.getElementById(this.method_button_id + mi.toString()).className = (mi == method ? "on" : "");
        }
        let result = 0;
        for (let ri = 0; ri < this.n_results; ri++) {
          if (document.getElementById(this.result_button_id + ri.toString()).className == "on") {
            result = ri;
          }
        }
        this.select_object(method, result);
      }
    
      select_scene(scene) {
        for (let si = 0; si < this.n_scenes; si++) {
          document.getElementById(this.scene_button_id + si.toString()).className = (si == scene ? "on" : "");
        }
        let scene_name = document.getElementById(this.scene_button_id + scene.toString()).value;
        for (let mi = 0; mi < this.n_methods; mi++) {
          let method_name = document.getElementById(this.method_button_id + mi.toString()).value;
          for (let ri = 0; ri < this.n_results; ri++) {
            let result_name = document.getElementById(this.result_button_id + ri.toString()).value;
            let o = document.getElementById(this.object_tag_id + "_" + mi.toString() + "_" + ri.toString());
            o.src = this.subdir + "/" + scene_name + "/" + method_name + "/" + result_name + "." + this.ext;
          }
        }
      }
    
      register() {
        for (let i = 0; i < this.n_scenes; i++) {
          document.getElementById(this.scene_button_id + i.toString()).addEventListener("click", function() { this.select_scene(i); }.bind(this, i));
        }
      
        for (let i = 0; i < this.n_methods; i++) {
          document.getElementById(this.method_button_id + i.toString()).addEventListener("click", function() { this.select_method(i); }.bind(this, i));
        }
      
        for (let i = 0; i < this.n_results; i++) {
          document.getElementById(this.result_button_id + i.toString()).addEventListener("click", function() { this.select_result(i); }.bind(this, i));
        }
      }
    }

    let ImageHandlerMixin = (superclass) => class extends superclass {
      get subdir() {
        return "images";
      }
    
      get ext() {
        return "png";
      }
    };

    let VideoHandlerMixin = (superclass) => class extends superclass {
      get subdir() {
        return "videos";
      }
    
      get ext() {
        return "mp4";
      }
    
      get paused() {
        return this.first_object.paused;
      }
    
      sync_video(e) {
        if (e === undefined) {
          return;
        }
        this.for_each_object(function(o) {
          if (o != e.currentTarget) {
            o.currentTime = e.currentTarget.currentTime;
          }
        });
      }
    
      play_video(e) {
        this.sync_video(e);
        this.for_each_object(function(o) { o.play(); });
      }
    
      pause_video(e) {
        this.for_each_object(function(o) { o.pause(); });
        this.sync_video(e);
      }
    
      on_object_selected(o) {
        o.addEventListener("play", this);
        o.addEventListener("pause", this);
        o.addEventListener("seeking", this);
        o.addEventListener("seeked", this);
        o.addEventListener("playing", this);
      }
    
      on_object_deselected(o) {
        o.removeEventListener("play", this);
        o.removeEventListener("pause", this);
        o.removeEventListener("seeking", this);
        o.removeEventListener("seeked", this);
        o.removeEventListener("playing", this);
      }
    
      handleEvent(e) {
        switch (e.type) {
          case "play": this.play_video(e); break;
          case "pause": this.pause_video(e); break;
          case "seeking": this.sync_video(e); break;
          case "seeked": this.sync_video(e); break;
          case "playing": this.sync_video(e); break;
        }
      }
    
      select_scene(j) {
        let autoplay = !this.paused;
        super.select_scene(j)
        if (autoplay) {
          this.play_video();
        }
      }
    
      register() {
        super.register();
        this.for_each_object(function(o) { o.muted = true; });
      }
    };

    class ImageHandler extends ImageHandlerMixin(ObjectHandler) {
    }

    class VideoHandler extends VideoHandlerMixin(ObjectHandler) {
    }

    class ImageHandler3 extends ImageHandlerMixin(ObjectHandler3) {
    }

    class VideoHandler3 extends VideoHandlerMixin(ObjectHandler3) {
    }

    window.onload = function() {
      intrinsics_handler = new VideoHandler3(7, 3, 6, "intrinsics_scene", "intrinsics_method", "intrinsics_result", "intrinsics");
      intrinsics_handler.register();
      try {
        intrinsics_handler.play_video();
      } catch (e) {
      }
    
      applications_handler = new VideoHandler3(7, 3, 4, "applications_scene", "applications_method", "applications_result", "applications");
      applications_handler.register();
      try {
        applications_handler.play_video();
      } catch (e) {
      }
    
      moving_light_handler = new VideoHandler3(3, 3, 1, "moving_light_scene", "moving_light_method", "moving_light_result", "moving_light");
      moving_light_handler.register();
      try {
        moving_light_handler.play_video();
      } catch (e) {
      }
    
      intrinsics_images_handler = new ImageHandler3(4, 7, 5, "intrinsics_images_scene", "intrinsics_images_method", "intrinsics_images_result", "intrinsics_images");
      intrinsics_images_handler.register();
    };
    </script>
</head>
<body>

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">👁️ IRIS: <font style="color:#19297C;">I</font>nverse <font style="color:#19297C;">R</font>endering of <font style="color:#19297C;">I</font>ndoor <font style="color:#19297C;">S</font>cenes <br/> from Low Dynamic Range Images</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://zhihao-lin.github.io/">Zhi-Hao Lin</a><sup>1,2</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://jbhuang0604.github.io">Jia-Bin Huang</a><sup>1,3</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?hl=zh-CN&user=Nxc2RbQAAAAJ&view_op=list_works&sortby=pubdate">Zhengqin Li</a><sup>1</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="http://flycooler.com">Zhao Dong</a><sup>1</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://richardt.name/">Christian Richardt</a><sup>1</sup>&nbsp</span>
            <br/>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://scholar.google.com/citations?user=jGQeuBUAAAAJ">Tuotuo Li</a><sup>1</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://zollhoefer.com/">Michael Zollhöfer</a><sup>1</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://johanneskopf.de/">Johannes Kopf</a><sup>1</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://shenlong.web.illinois.edu/">Shenlong Wang</a><sup>2</sup>&nbsp</span>
            <span class="author-block">
              <a target="_blank" rel="noopener noreferrer" href="https://changilkim.com">Changil Kim</a><sup>1</sup>&nbsp</span>
            
            
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>Meta</span>&nbsp
            <span class="author-block"><sup>2</sup>University of Illinois Urbana-Champaign</span>&nbsp
            <span class="author-block"><sup>3</sup>University of Maryland, College Park</span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href="https://arxiv.org/abs/2401.12977"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- <span class="link-block">
                <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span> -->
              
              <!-- Result Link. -->
              <span class="link-block">
                <a href="#results"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="far fa-images"></i>
                  </span>
                  <span>Results</span>
                  </a>
              </span>
              <!-- Code Link. -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (Coming Soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-bedroom">
          <video class="car" poster="" id="bedroom" autoplay controls muted loop playsinline height="100%">
            <source src="videos/teaser/bedroom.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-conferenceroom">
          <video class="car" poster="" id="conferenceroom" autoplay controls muted loop playsinline height="100%">
            <source src="videos/teaser/conferenceroom.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-bathroom">
          <video class="car" poster="" id="bathroom" autoplay controls muted loop playsinline height="100%">
            <source src="videos/teaser/bathroom.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-classroom">
          <video class="car" poster="" id="classroom" autoplay controls muted loop playsinline height="100%">
            <source src="videos/teaser/classroom.mp4"
                    type="video/mp4">
          </video>
        </div>

        <div class="item item-kitchen">
          <video class="car" poster="" id="kitchen" autoplay controls muted loop playsinline height="100%">
            <source src="videos/teaser/kitchen.mp4"
                    type="video/mp4">
          </video>
        </div>
        
        <div class="item item-livingroom">
          <video class="car" poster="" id="livingroom" autoplay controls muted loop playsinline height="100%">
            <source src="videos/teaser/livingroom.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <!-- <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video> -->
      <img src="images/figures/teaser.png">
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">IRIS</span> 
          estimates accurate material, lighting, and camera response function given a set of LDR images and scene geometry, 
          enabling photorealistic and view-consistent relighting and object insertion.
      </h2>
    </div>
  </div>
</section>





<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            While numerous 3D reconstruction and novel-view synthesis methods allow for photorealistic rendering of a scene from multi-view images easily captured with consumer cameras, 
            they bake illumination in their representations and fall short of supporting advanced applications like material editing, relighting, and virtual object insertion.
            The reconstruction of physically based material properties and lighting via inverse rendering promises to enable such applications.
            However, most inverse rendering techniques require high dynamic range (HDR) images as input, a setting that is inaccessible to most users.
            We present a method that recovers the physically based material properties and spatially-varying HDR lighting of a scene from multi-view, low-dynamic-range (LDR) images.
          </p>
          <p>
            We model the LDR image formation process in our inverse rendering pipeline and propose a novel optimization strategy for material, lighting, and a camera response model.
            We evaluate our approach with synthetic and real scenes compared to the state-of-the-art inverse rendering methods that take either LDR or HDR input.
            Our method outperforms existing methods taking LDR images as input, and allows for highly realistic relighting and object insertion.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src=""
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered">
      <div class="column is-full-width">
        <!-- Interactive -->
        <h2 id="results" class="title is-3">
          Results
        </h2>
        <!-- <div class="result">
          <button>Cross-category</button>
        </div> -->
        <p>Click and jump to:</p>
        
        <span class="link-block">
          <a href="#intrinsics"
             class="external-link button is-normal is-rounded is-primary is-light">
            <span>Material & Lighting</span>
            </a>
        </span>
        <span class="link-block">
          <a href="#intrinsics_images"
             class="external-link button is-normal is-rounded is-info is-light">
            <span>Ground Truth Comparisons</span>
            </a>
        </span>
        <span class="link-block">
          <a href="#applications"
             class="external-link button is-normal is-rounded is-danger is-light">
            <span>Relighting & Insertion</span>
            </a>
        </span>
        <span class="link-block">
          <a href="#moving_light"
             class="external-link button is-normal is-rounded is-warning is-light">
            <span>Moving Light Source</span>
            </a>
        </span>

        
        <br/><br/>
        <h3 id="intrinsics" class="title is-4">
          Material and Lighting Qualitative Comparisons
          <span><a href="#results">&uarr;</a></span>
        </h3>
        <p>
          We use
          <a target="_blank" rel="noopener noreferrer" href="https://jerrypiglet.github.io/fipt-ucsd/">FIPT(HDR)</a> as reference, which takes in HDR images as input.<br/>
          Baseline FIPT*(LDR) takes LDR images and estimated emission masks as input.<br/>
          The roughness <i>&sigma;</i> and metallic <i>m</i> are visualized with OPENCV MAGMA colormap (from left to right: 0~1): <img id="magma" src="images/figures/colorscale_magma.jpg"/><br/>
          For the HDR emission <b>L</b><sub><i>e</i></sub> , we mask the non-emitter region in <font color="blue">blue</font>, and show tonemapped emission otherwise, such that it is not saturated and difference is visible.
        </p>
        <div class="column frame">
          <div class="content has-text-justified">
            <div class="flex">
              <div>
                <div class="flex">
                  <div class="result">
                    <p class="btncap">Real (FIPT)</p>
                    <button id="intrinsics_scene0" value="real_conferenceroom" class="on">Conference Room</button>
                    <button id="intrinsics_scene1" value="real_classroom">Classroom</button>
                    <p class="btncap">Real (ScanNet++)</p>
                    <button id="intrinsics_scene2" value="scannetpp_empty">Empty Room</button>
                    <button id="intrinsics_scene3" value="scannetpp_lab">Lab 0</button>
                    <button id="intrinsics_scene4" value="scannetpp_office3">Office</button>
                    <button id="intrinsics_scene5" value="scannetpp_lab2">Lab 1</button>
                    <button id="intrinsics_scene6" value="scannetpp_engine">Engine Room</button>
                  </div>
                  <div class="result">
                    <p class="btncap">Methods (LDR input)</p>
                    <button id="intrinsics_method0" value="ours" class="on">Ours</button>
                    <button id="intrinsics_method2" value="fipt_ldr">FIPT*</button>
                    <p class="btncap">Methods (HDR input)</p>
                    <button id="intrinsics_method1" value="fipt_hdr">FIPT</button>
                  </div>
                  <div class="result">
                    <p class="btncap">Results</p>
                    <button id="intrinsics_result0" value="intrinsics/kd">Diffuse Reflectance<b>k</b><sub><i>d</i></sub></button>
                    <button id="intrinsics_result1" value="intrinsics/a_prime">Material Reflectance <b>a</b>&prime;</button>
                    <button id="intrinsics_result2" value="intrinsics/roughness">Roughness <i>&sigma;</i></button>
                    <button id="intrinsics_result3" value="intrinsics/metallic">Metallic <i>m</i></button>
                    <button id="intrinsics_result4" value="intrinsics/emission">Tonemapped HDR Emission <b>L</b><sub><i>e</i></sub></button>
                    <button id="intrinsics_result5" value="intrinsics/rgb_full" class="on">Rerendering <b>L</b></button>
                  </div>
                </div>
                <!-- <div class="desc">
                  <p><b>Input Style and Input Images.</b> Select an input style, the input images are used to transfer texture to the target mesh.</p>
                  <p><b>Meshes.</b> We demonstrate image-guided texture transfer to diverse meshes from selected input images.</p>
                  <p><b>Baselines.</b> We compare our method with existing methods TEXTure [<a href="#reference">1</a>] and LatentPaint[<a href="#reference">2</a>], which can also synthesize textures for meshes given a few input images.</p>
                </div> -->
              </div>
              <div>
                <video id="intrinsics_0_0" controls loop>
                  <source src="videos/real_conferenceroom/ours/intrinsics/kd.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_0_1" controls loop>
                  <source src="videos/real_conferenceroom/ours/intrinsics/a_prime.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_0_2" controls loop>
                  <source src="videos/real_conferenceroom/ours/intrinsics/roughness.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_0_3" controls loop>
                  <source src="videos/real_conferenceroom/ours/intrinsics/metallic.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_0_4" controls loop>
                  <source src="videos/real_conferenceroom/ours/intrinsics/emission.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_0_5" controls loop class="on">
                  <source src="videos/real_conferenceroom/ours/intrinsics/rgb_full.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_1_0" controls loop>
                  <source src="videos/real_conferenceroom/fipt_hdr/intrinsics/kd.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_1_1" controls loop>
                  <source src="videos/real_conferenceroom/fipt_hdr/intrinsics/a_prime.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_1_2" controls loop>
                  <source src="videos/real_conferenceroom/fipt_hdr/intrinsics/roughness.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_1_3" controls loop>
                  <source src="videos/real_conferenceroom/fipt_hdr/intrinsics/metallic.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_1_4" controls loop>
                  <source src="videos/real_conferenceroom/fipt_hdr/intrinsics/emission.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_1_5" controls loop>
                  <source src="videos/real_conferenceroom/fipt_hdr/intrinsics/rgb_full.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_2_0" controls loop>
                  <source src="videos/real_conferenceroom/fipt_ldr/intrinsics/kd.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_2_1" controls loop>
                  <source src="videos/real_conferenceroom/fipt_ldr/intrinsics/a_prime.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_2_2" controls loop>
                  <source src="videos/real_conferenceroom/fipt_ldr/intrinsics/roughness.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_2_3" controls loop>
                  <source src="videos/real_conferenceroom/fipt_ldr/intrinsics/metallic.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_2_4" controls loop>
                  <source src="videos/real_conferenceroom/fipt_ldr/intrinsics/emission.mp4" type="video/mp4"/>
                </video>
                <video id="intrinsics_2_5" controls loop>
                  <source src="videos/real_conferenceroom/fipt_ldr/intrinsics/rgb_full.mp4" type="video/mp4"/>
                </video>
              </div>
            </div>
          </div>

        </div>

        <br/><br/>
        <h3 id="intrinsics_images" class="title is-4">
          Material and Lighting Comparisons with Ground Truth
          <span><a href="#results">&uarr;</a></span>
        </h3>
        <p>
          In addition to <a target="_blank" rel="noopener noreferrer" href="https://jerrypiglet.github.io/fipt-ucsd/">FIPT(HDR)</a> and FIPT*(LDR), 
          we also compare the material & lighting estimation with <a target="_blank" rel="noopener noreferrer" href="https://github.com/apple/ml-neilf">NeILF</a>,
          <a target="_blank" rel="noopener noreferrer" href="https://jingsenzhu.github.io/i2-sdf/">I<sup>2</sup>-SDF</a>, 
          and <a target="_blank" rel="noopener noreferrer" href="https://github.com/ViLab-UCSD/IndoorLightEditing">Li et al. 2022</a>. <br/>
          We thank the authors of <a target="_blank" rel="noopener noreferrer" href="https://jingsenzhu.github.io/i2-sdf/">I<sup>2</sup>-SDF</a> and 
          and <a target="_blank" rel="noopener noreferrer" href="https://github.com/ViLab-UCSD/IndoorLightEditing">Li et al. 2022</a> for providing the results. <br/>
          The roughness <i>&sigma;</i> is visualized with OPENCV MAGMA colormap (from left to right: 0~1): <img id="magma" src="images/figures/colorscale_magma.jpg"/><br/>
          For the HDR emission <b>L</b><sub><i>e</i></sub> , we mask the non-emitter region in <font color="blue">blue</font>, and show tonemapped emission otherwise, such that it is not saturated and difference is visible.
        </p>
        <div class="column frame">
          <div class="flex">
            <div>
              <div class="flex">
                <div class="result">
                  <p class="btncap">Synthetic (FIPT)</p>
                  <button id="intrinsics_images_scene0" value="synthetic_kitchen" class="on">Kitchen</button>
                  <button id="intrinsics_images_scene1" value="synthetic_livingroom">Living Room</button>
                  <button id="intrinsics_images_scene2" value="synthetic_bedroom">Bedroom</button>
                  <button id="intrinsics_images_scene3" value="synthetic_bathroom">Bathroom</button>
                  
                </div>
                <div class="wider_buttons result">
                  <p class="btncap">Methods (LDR input)</p>
                  <button id="intrinsics_images_method0" value="ours" class="on">Ours</button>
                  <button id="intrinsics_images_method2" value="fipt_ldr">FIPT*</button>
                  <button id="intrinsics_images_method3" value="neilf">NeILF</button>
                  <button id="intrinsics_images_method4" value="i2_sdf">I<sup>2</sup>-SDF</button>
                  <button id="intrinsics_images_method5" value="li22">Li et al. 2022</button>
                  <p class="btncap">Methods (HDR input)</p>
                  <button id="intrinsics_images_method1" value="fipt_hdr">FIPT</button>
                  <button id="intrinsics_images_method6" value="gt">Ground Truth</button>
                </div>
                <div class="wider_buttons result">
                  <p class="btncap">Results</p>
                  <button id="intrinsics_images_result0" value="kd" class="on">Diffuse Reflectance <b>k</b><sub><i>d</i></sub></button>
                  <button id="intrinsics_images_result1" value="a_prime">Material Reflectance <b>a</b>&prime;</button>
                  <button id="intrinsics_images_result2" value="roughness">Roughness <i>&sigma;</i></button>
                  <button id="intrinsics_images_result3" value="emission">Tonemapped HDR Emission <b>L</b><sub><i>e</i></sub></button>
                  <button id="intrinsics_images_result4" value="rgb">Rerendering <b>L</b></button>
                </div>
              </div>
              <!-- <div class="desc">
                <p><b>Input Style and Input Images.</b> Select an input style, the input images are used to transfer texture to the target mesh.</p>
                <p><b>Meshes.</b> We demonstrate image-guided texture transfer to diverse meshes from selected input images.</p>
                <p><b>Baselines.</b> We compare our method with existing methods TEXTure [<a href="#reference">1</a>] and LatentPaint[<a href="#reference">2</a>], which can also synthesize textures for meshes given a few input images.</p>
              </div> -->
            </div>
            <div>
              <img id="intrinsics_images_0_0" src="images/synthetic_kitchen/ours/kd.png" class="on"/>
              <img id="intrinsics_images_0_1" src="images/synthetic_kitchen/ours/a_prime.png"/>
              <img id="intrinsics_images_0_2" src="images/synthetic_kitchen/ours/roughness.png"/>
              <img id="intrinsics_images_0_3" src="images/synthetic_kitchen/ours/emission.png"/>
              <img id="intrinsics_images_0_4" src="images/synthetic_kitchen/ours/rgb.png"/>
              <img id="intrinsics_images_1_0" src="images/synthetic_kitchen/fipt_hdr/kd.png"/>
              <img id="intrinsics_images_1_1" src="images/synthetic_kitchen/fipt_hdr/a_prime.png"/>
              <img id="intrinsics_images_1_2" src="images/synthetic_kitchen/fipt_hdr/roughness.png"/>
              <img id="intrinsics_images_1_3" src="images/synthetic_kitchen/fipt_hdr/emission.png"/>
              <img id="intrinsics_images_1_4" src="images/synthetic_kitchen/fipt_hdr/rgb.png"/>
              <img id="intrinsics_images_2_0" src="images/synthetic_kitchen/fipt_ldr/kd.png"/>
              <img id="intrinsics_images_2_1" src="images/synthetic_kitchen/fipt_ldr/a_prime.png"/>
              <img id="intrinsics_images_2_2" src="images/synthetic_kitchen/fipt_ldr/roughness.png"/>
              <img id="intrinsics_images_2_3" src="images/synthetic_kitchen/fipt_ldr/emission.png"/>
              <img id="intrinsics_images_2_4" src="images/synthetic_kitchen/fipt_ldr/rgb.png"/>
              <img id="intrinsics_images_3_0" src="images/synthetic_kitchen/neilf/kd.png"/>
              <img id="intrinsics_images_3_1" src="images/synthetic_kitchen/neilf/a_prime.png"/>
              <img id="intrinsics_images_3_2" src="images/synthetic_kitchen/neilf/roughness.png"/>
              <img id="intrinsics_images_3_3" src="images/synthetic_kitchen/neilf/emission.png"/>
              <img id="intrinsics_images_3_4" src="images/synthetic_kitchen/neilf/rgb.png"/>
              <img id="intrinsics_images_4_0" src="images/synthetic_kitchen/i2_sdf/kd.png"/>
              <img id="intrinsics_images_4_1" src="images/synthetic_kitchen/i2_sdf/a_prime.png"/>
              <img id="intrinsics_images_4_2" src="images/synthetic_kitchen/i2_sdf/roughness.png"/>
              <img id="intrinsics_images_4_3" src="images/synthetic_kitchen/i2_sdf/emission.png"/>
              <img id="intrinsics_images_4_4" src="images/synthetic_kitchen/i2_sdf/rgb.png"/>
              <img id="intrinsics_images_5_0" src="images/synthetic_kitchen/li22/kd.png"/>
              <img id="intrinsics_images_5_1" src="images/synthetic_kitchen/li22/a_prime.png"/>
              <img id="intrinsics_images_5_2" src="images/synthetic_kitchen/li22/roughness.png"/>
              <img id="intrinsics_images_5_3" src="images/synthetic_kitchen/li22/emission.png"/>
              <img id="intrinsics_images_5_4" src="images/synthetic_kitchen/li22/rgb.png"/>
              <img id="intrinsics_images_6_0" src="images/synthetic_kitchen/gt/kd.png"/>
              <img id="intrinsics_images_6_1" src="images/synthetic_kitchen/gt/a_prime.png"/>
              <img id="intrinsics_images_6_2" src="images/synthetic_kitchen/gt/roughness.png"/>
              <img id="intrinsics_images_6_3" src="images/synthetic_kitchen/gt/emission.png"/>
              <img id="intrinsics_images_6_4" src="images/synthetic_kitchen/gt/rgb.png"/>
            </div>
          </div>

        </div>

        <br/><br/>
        <h3 id="applications" class="title is-4">
          Relighting and Object Insertion Comparisons
          <span><a href="#results">&uarr;</a></span>
        </h3>
        <p>
          We use
          <a target="_blank" rel="noopener noreferrer" href="https://jerrypiglet.github.io/fipt-ucsd/">FIPT(HDR)</a> as reference, which takes in HDR images as input.<br/>
          Baseline FIPT*(LDR) takes LDR images and estimated emission masks as input.<br/>
        </p>
        <div class="column frame">
          <div class="flex">
            <div>
              <div class="flex">
                <div class="result">
                  <p class="btncap">Real (FIPT)</p>
                  <button id="applications_scene0" value="real_conferenceroom" class="on">Conference Room</button>
                  <button id="applications_scene1" value="real_classroom">Classroom</button>
                  <p class="btncap">Real (ScanNet++)</p>
                  <button id="applications_scene2" value="scannetpp_empty">Empty Room</button>
                  <button id="applications_scene3" value="scannetpp_lab">Lab 0</button>
                  <button id="applications_scene4" value="scannetpp_office3">Office</button>
                  <button id="applications_scene5" value="scannetpp_lab2">Lab 1</button>
                  <button id="applications_scene6" value="scannetpp_engine">Engine Room</button>
                </div>
                <div class="result">
                  <p class="btncap">Methods (LDR input)</p>
                  <button id="applications_method0" value="ours" class="on">Ours</button>
                  <button id="applications_method1" value="fipt_ldr">FIPT*</button>
                  <p class="btncap">Methods (HDR input)</p>
                  <button id="applications_method2" value="fipt_hdr">FIPT</button>
                </div>
                <div class="result">
                  <p class="btncap">Applications</p>
                  <button id="applications_result0" value="relight_0" class="on">Relighting 0</button>
                  <button id="applications_result1" value="relight_1">Relighting 1</button>
                  <button id="applications_result2" value="insert">Object Insertion</button>
                  <button id="applications_result3" value="intrinsics/rgb_full">Original Lighting</button>
                </div>
              </div>
              <!-- <div class="desc">
                <p><b>Input Style and Input Images.</b> Select an input style, the input images are used to transfer texture to the target mesh.</p>
                <p><b>Meshes.</b> We demonstrate image-guided texture transfer to diverse meshes from selected input images.</p>
                <p><b>Baselines.</b> We compare our method with existing methods TEXTure [<a href="#reference">1</a>] and LatentPaint[<a href="#reference">2</a>], which can also synthesize textures for meshes given a few input images.</p>
              </div> -->
            </div>
            <div>
              <video id="applications_0_0" controls loop class="on">
                <source src="videos/real_conferenceroom/ours/relight_0.mp4" type="video/mp4"/>
              </video>
              <video id="applications_0_1" controls loop>
                <source src="videos/real_conferenceroom/ours/relight_1.mp4" type="video/mp4"/>
              </video>
              <video id="applications_0_2" controls loop>
                <source src="videos/real_conferenceroom/ours/insert.mp4" type="video/mp4"/>
              </video>
              <video id="applications_0_3" controls loop>
                <source src="videos/real_conferenceroom/ours/intrinsics/rgb_full.mp4" type="video/mp4"/>
              </video>
              <video id="applications_1_0" controls loop>
                <source src="videos/real_conferenceroom/fipt_ldr/relight_0.mp4" type="video/mp4"/>
              </video>
              <video id="applications_1_1" controls loop>
                <source src="videos/real_conferenceroom/fipt_ldr/relight_1.mp4" type="video/mp4"/>
              </video>
              <video id="applications_1_2" controls loop>
                <source src="videos/real_conferenceroom/fipt_ldr/insert.mp4" type="video/mp4"/>
              </video>
              <video id="applications_1_3" controls loop>
                <source src="videos/real_conferenceroom/fipt_ldr/intrinsics/rgb_full.mp4" type="video/mp4"/>
              </video>
              <video id="applications_2_0" controls loop>
                <source src="videos/real_conferenceroom/fipt_hdr/relight_0.mp4" type="video/mp4"/>
              </video>
              <video id="applications_2_1" controls loop>
                <source src="videos/real_conferenceroom/fipt_hdr/relight_1.mp4" type="video/mp4"/>
              </video>
              <video id="applications_2_2" controls loop>
                <source src="videos/real_conferenceroom/fipt_hdr/insert.mp4" type="video/mp4"/>
              </video>
              <video id="applications_2_3" controls loop>
                <source src="videos/real_conferenceroom/fipt_hdr/intrinsics/rgb_full.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>

        </div>

        <br/><br/>
        <h3 id="moving_light" class="title is-4">
          Comparisons with Moving Light Source
          <span><a href="#results">&uarr;</a></span>
        </h3>
        <p>
          We use
          <a target="_blank" rel="noopener noreferrer" href="https://jerrypiglet.github.io/fipt-ucsd/">FIPT(HDR)</a> as reference, which takes in HDR images as input.<br/>
          Baseline FIPT*(LDR) takes LDR images and estimated emission masks as input.<br/>
        </p>
        <div class="column frame">
          <div class="flex">
            <div>
              <div class="flex">
                <div class="result">
                  <p class="btncap">Synthetic (FIPT)</p>
                  <button id="moving_light_scene0" value="synthetic_bedroom" class="on">Bedroom</button>
                  <button id="moving_light_scene1" value="synthetic_bathroom">Bathroom</button>
                  <p class="btncap">Real (FIPT)</p>
                  <button id="moving_light_scene2" value="real_classroom">Classroom</button>
                </div>
                <div class="result">
                  <p class="btncap">Methods (LDR input)</p>
                  <button id="moving_light_method0" value="ours" class="on">Ours</button>
                  <button id="moving_light_method1" value="fipt_ldr">FIPT*</button>
                  <p class="btncap">Methods (HDR input)</p>
                  <button id="moving_light_method2" value="fipt_hdr">FIPT</button>
                </div>
                <div class="result">
                  <p class="btncap">Results</p>
                  <button id="moving_light_result0" value="move" class="on">Relighting with Moving Light</button>
                </div>
              </div>
              <!-- <div class="desc">
                <p><b>Input Style and Input Images.</b> Select an input style, the input images are used to transfer texture to the target mesh.</p>
                <p><b>Meshes.</b> We demonstrate image-guided texture transfer to diverse meshes from selected input images.</p>
                <p><b>Baselines.</b> We compare our method with existing methods TEXTure [<a href="#reference">1</a>] and LatentPaint[<a href="#reference">2</a>], which can also synthesize textures for meshes given a few input images.</p>
              </div> -->
            </div>
            <div>
              <video id="moving_light_0_0" controls loop class="on">
                <source src="videos/synthetic_bedroom/ours/move.mp4" type="video/mp4"/>
              </video>
              <video id="moving_light_1_0" controls loop>
                <source src="videos/synthetic_bedroom/fipt_ldr/move.mp4" type="video/mp4"/>
              </video>
              <video id="moving_light_2_0" controls loop>
                <source src="videos/synthetic_bedroom/fipt_hdr/move.mp4" type="video/mp4"/>
              </video>
            </div>
          </div>

        </div>

        


        <!-- <br/><br/>
        <h3 id="crf" class="title is-4">
          Camera Response Function (CRF) Estimation
          <span><a href="#results">&uarr;</a></span>
        </h3>
        <div class="column frame">
          <div class="content has-text-justified">
            <p>
              Given input images with varying exposure, IRIS estimates camera response function (CRF). We compare with 3 baselines:<br/>
              - Mean CRF \(\bar{g}\): set CRF as constant mean curve of <a target="_blank" rel="noopener noreferrer" href="https://cave.cs.columbia.edu/repository/DoRF">empirical 201 CRFs</a> measured in real-world devices.<br/>
              - Gamma \(1/2.2\): set CRF as simple function: \( g(x) = x^{1/2.2} \), which is used in <a target="_blank" rel="noopener noreferrer" href="https://jerrypiglet.github.io/fipt-ucsd/">FIPT</a><br/>
              <font color="blue">Blue curve</font>: ground truth, <font color="red">Red curve</font>: estimation
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="images/figures/crf_input.png">
          </div>
        </div> -->
        

      </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Method</h2>
        <img src="images/figures/framework.png">
        <p>
          Given multi-view posed LDR images and a surface mesh, our inverse rendering pipeline is divided into two main stages.
          In the initialization stage, we initialize the BRDF, extract a surface light field, and estimate emitter geometry.
          In the optimization stage, we first recover HDR radiance from the LDR input, then bake shading maps, and jointly optimize BRDF and CRF parameters.
          These three steps are repeated until convergence.
        </p>
      </div>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">

    <!-- Animation. -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <!-- <h2 class="title is-3">Results</h2>
        <p>
            Additional results can be 
            found <a target="_blank" rel="noopener noreferrer" href="./static/results/index.html">here</a>.
        </p>
        <br/>
        <h3 class="title is-4">Image-guided texture synthesis</h3>
        <div class="content has-text-justified">
          <p>
            Given 3-5 images of an object, we synthesize textures for an 
            arbitrary mesh w.r.t. input images. 
          </p>
        </div>
        <div class="content has-text-centered">
            <img src="./static/images/results.jpg">
          </div>

          <h3 class="title is-4">Baseline Comparison</h3>
          <div class="content has-text-justified">
            <p>
              We compare our method with 
              <a target="_blank" rel="noopener noreferrer" href="https://github.com/eladrich/latent-nerf?tab=readme-ov-file#latent-paint-art">Latent-Paint</a> 
              and <a target="_blank" rel="noopener noreferrer" href="https://github.com/TEXTurePaper/TEXTurePaper?tab=readme-ov-file#3-run-texture-with-personalized-model">TEXTURE</a>.
            </p>
          </div>
          <div class="content has-text-centered">
            <img src="./static/images/baseline.jpg">
            </div> -->

          <!-- <h3 class="title is-4">Diversity</h3>
            <div class="content has-text-justified">
              <p>
                Our method can synthesize diverse patterns from the same set of images.
              </p>
            </div>
            <div class="content has-text-centered">
              <img src="./static/images/diversity.jpg">
              </div> -->

        <br/>
      </div>
    </div>

  </div>
</section>


<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{
}</code></pre>
  </div>
</section> -->


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is partially borrowed from <a
            href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>. 
            Please refer to Nerfies if you want to use this template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>